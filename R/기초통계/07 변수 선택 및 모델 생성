#==================================================
# 7. 모델생성
#==================================================
getwd()
setwd("c://temp//R")

# 7.1 Train Set & Test Set ---------------------------------------------------------
rm(list=ls())
#Sampling Indexes
titanic.0 <- read.csv("titanic.1.csv" 
                      , stringsAsFactors = F 
                      , na.strings=c("","NA","Unknown","NULL"))

titanic.0$Sex <- as.factor(titanic.0$Sex)
titanic.0$Survived <- as.factor(titanic.0$Survived)
titanic.0$Embarked <- as.factor(titanic.0$Embarked)
titanic.0$Pclass <- as.factor(titanic.0$Pclass)
titanic.0$AgeGroup <- as.factor(titanic.0$AgeGroup)

?sample
sample(1:100, size = 10)
nrow(titanic.0)

set.seed(2019)
indexes <- sample(1:nrow(titanic.0)
                  , size=0.3*nrow(titanic.0))

indexes
# Split data
test <- titanic.0[indexes,]
train <- titanic.0[-indexes,]
nrow(test)
nrow(train)

# 데이터 들여다보기
# 주요 변수의 비율 비교 : titanic.0, train, test
table(titanic.0$Sex)
table(titanic.0$Survived)
prop.table(table(titanic.0$Sex))
prop.table(table(train$Sex))
prop.table(table(test$Sex))

prop.table(table(titanic.0$Survived))
prop.table(table(train$Survived))
prop.table(table(test$Survived))


# 7.2 변수 선택하기 : 전진선택법 ---------------------------------------------------
glm.base <- glm(Survived~1, family=binomial, data = train)
str(train)
forward.aic <- step(glm.base
                    , Survived~Age+Embarked+Fare+Sex+Pclass+SibSp+Parch+Family+AgeGroup
                    ,direction = "forward")

# Survived ~ Sex + Pclass + Age + SibSp  + Embarked
# Survived ~ Sex + Pclass + AgeGroup + SibSp  + Embarked
# 내가선택된 변수 ==>  Sex + Pclass + Age + Embarked + Fare

# 7.3 머신러닝 알고리즘 : 로지스틱회귀 ---------------------------------------------

#모델생성
train.glm.1 <- glm(Survived ~ Sex + Pclass + Age + SibSp  + Embarked
                   , family = binomial
                   , data = train)

train.glm.2 <- glm(Survived ~ Sex + Pclass + AgeGroup + SibSp  + Embarked
                   , family = binomial
                   , data = train)

train.glm.3 <- glm(Survived ~ Sex + Pclass + Age + Embarked + Fare
                   , family = binomial
                   , data = train)
#예측
head(test)
fit.results.1 <- predict(train.glm.1, newdata=test[,-2], type='response')
fit.results.2 <- predict(train.glm.2, newdata=test[,-2], type='response')
fit.results.3 <- predict(train.glm.3, newdata=test[,-2], type='response')
fit.results.1

#==================================================
# 8. 검증
#==================================================

# 8.1 ROC(Receiver Operating Curve) --------------

install.packages("Epi")
require(Epi)

ROC(fit.results.1,test$Survived  ) # 0.404, 0.864
ROC(fit.results.2,test$Survived  ) # 0.389, 0.862
ROC(fit.results.3,test$Survived  ) # 0.415, 0.853

# 8.2 Cut-off value ----
# 0.657
# 0.598
# 1,0으로 바꿔주기 
fit.results.New.1 <- ifelse(fit.results.1 >= 0.404,1,0)
fit.results.New.2 <- ifelse(fit.results.2 >= 0.389,1,0)
fit.results.New.3 <- ifelse(fit.results.3 >= 0.415,1,0)

# 8.3 Confusion matrix -------------------------------
if(!require(caret)) install.packages("caret")
library(caret)
if(!require(e1071)) install.packages("e1071")
library(e1071)

# 수정된 부분 : confusionMatrix(예측값, 실제값)으로 실행
fit.results.New.1 <- as.factor(fit.results.New.1)
fit.results.New.2 <- as.factor(fit.results.New.2)
fit.results.New.3 <- as.factor(fit.results.New.3)

confusionMatrix(fit.results.New.1,test$Survived)
confusionMatrix(fit.results.New.2,test$Survived)
confusionMatrix(fit.results.New.3,test$Survived)
